{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "\n",
    "## Plotting Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.14248671  1.12930053]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123d84150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def sigmoid(x, x0, k):\n",
    "    y = 1 / (1 + np.exp(-k*(x-x0)))\n",
    "    return y\n",
    "\n",
    "xdata = np.array([0.0,   1.0,  3.0, 4.3, 7.0,   8.0,   8.5, 10.0, 12.0])\n",
    "ydata = np.array([0.01, 0.02, 0.04, 0.11, 0.43,  0.7, 0.89, 0.95, 0.99])\n",
    "\n",
    "popt, pcov = curve_fit(sigmoid, xdata, ydata)\n",
    "print popt\n",
    "\n",
    "x = np.linspace(-50, 50, 50)\n",
    "y = sigmoid(x, *popt)\n",
    "\n",
    "plt.plot(xdata, ydata, 'o', label='data')\n",
    "plt.plot(x,y, label='fit')\n",
    "plt.plot(range(-12, 25), [0.5]*37, \"b-\")\n",
    "plt.xlim(-10, 20)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jay/miniconda3/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "X_clf = array[:,0:8]\n",
    "Y_clf = array[:,8]\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_clf, X_test_clf, Y_train_clf, Y_test_clf = model_selection.train_test_split(X_clf, Y_clf, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(random_state=7)\n",
    "logistic.fit(X_train_clf, Y_train_clf)\n",
    "y_predict_clf = logistic.predict(X_test_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75590551181102361"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test_clf, y_predict_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# y_pred = [0, 2, 1, 3]\n",
    "# y_true = [0, 1, 2, 3]\n",
    "# accuracy = accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782101167315\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_clf, Y_train_clf)\n",
    "expected = Y_train_clf\n",
    "predicted = model.predict(X_train_clf)\n",
    "print(accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Cross-validation\n",
    "\n",
    "Quite often, we use cross-validation techniques, and use the evaluation metrics to evaluate each round's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.770 (0.048)\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "\n",
    "results = model_selection.cross_val_score(model, X_clf, Y_clf, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: {:.3f} ({:.3f})\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Loss\n",
    "\n",
    "An example of calculating logloss for Logistic regression predictions on the Pima Indians onset of diabetes dataset.\n",
    "\n",
    "* logloss nearer to 0 is better, with 0 representing a perfect logloss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: -0.493, +/-0.047\n"
     ]
    }
   ],
   "source": [
    "scoring = 'neg_log_loss'\n",
    "results = model_selection.cross_val_score(model, X_clf, Y_clf, cv=kfold, scoring=scoring)\n",
    "print(\"Logloss: {:.3f}, +/-{:.3f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[141,  21],\n",
       "       [ 41,  51]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_clf, Y_train_clf)\n",
    "\n",
    "predicted = model.predict(X_test_clf)\n",
    "matrix = confusion_matrix(Y_test_clf, predicted)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.618 +/-0.054\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "\n",
    "scoring = 'f1'\n",
    "\n",
    "results = model_selection.cross_val_score(model, X_clf, Y_clf, cv=kfold, scoring=scoring)\n",
    "print(\"f1 score: {:.3f} +/-{:.3f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area Under ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "\n",
    "results = model_selection.cross_val_score(model, X_clf, Y_clf, cv=kfold, scoring=scoring)\n",
    "print(\"AUC: {:.3f} ({:.3f})\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report\n",
    "\n",
    "* Scikit-learn does provide a convenience report when working on classification problems to give you a quick idea of the accuracy of a model using a number of measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.87      0.82       162\n",
      "        1.0       0.71      0.55      0.62        92\n",
      "\n",
      "avg / total       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_clf, Y_train_clf)\n",
    "predicted = model.predict(X_test_clf)\n",
    "\n",
    "report = classification_report(Y_test_clf, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Metrics\n",
    "\n",
    "## Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -4.005 (2.084)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = pandas.read_csv(url, delim_whitespace=True, names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "X_reg = array[:,0:13]\n",
    "Y_reg = array[:,13]\n",
    "seed = 7\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LinearRegression()\n",
    "\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "\n",
    "results = model_selection.cross_val_score(model, X_reg, Y_reg, cv=kfold, scoring=scoring)\n",
    "print(\"MAE: {:.3f} ({:.3f})\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -34.705 (45.574)\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LinearRegression()\n",
    "\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "results = model_selection.cross_val_score(model, X_reg, Y_reg, cv=kfold, scoring=scoring)\n",
    "print(\"MSE: {:.3f} ({:.3f})\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $R^2$ Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R sq: 0.203 (0.595)\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LinearRegression()\n",
    "\n",
    "scoring = 'r2'\n",
    "\n",
    "results = model_selection.cross_val_score(model, X_reg, Y_reg, cv=kfold, scoring=scoring)\n",
    "print(\"R sq: {:.3f} ({:.3f})\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "The following code evaluates different alpha values for the Ridge Regression algorithm on the diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0}\n",
      "-0.665626531816\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jay/miniconda3/envs/py27/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for Algorithm Tuning\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(X_reg, Y_reg)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "\n",
    "The following code evaluates different alpha random values between 0 and 1 for the Ridge Regression algorithm on the diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.99233806322310969, copy_X=True, fit_intercept=True,\n",
      "   max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "   tol=0.001)\n",
      "-0.668170992108\n",
      "0.992338063223\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'alpha': sp_rand()}\n",
    "\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\n",
    "rsearch.fit(X_reg, Y_reg)\n",
    "print(rsearch.best_estimator_)\n",
    "\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search vs Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get some data\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "n_iter_search = 100\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 27.46 seconds for 100 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.932 (std: 0.009)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 2, 'criterion': 'entropy', 'max_features': 5, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.928 (std: 0.006)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 4, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 7, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.927 (std: 0.011)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 2, 'criterion': 'gini', 'max_features': 9, 'max_depth': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'bootstrap': [True, False], 'min_samples_leaf': [1, 3, 10], 'min_samples_split': [2, 3, 10], 'criterion': ['gini', 'entropy'], 'max_features': [1, 3, 10], 'max_depth': [3, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 56.72 seconds for 216 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.934 (std: 0.003)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 10, 'criterion': 'gini', 'max_features': 3, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.934 (std: 0.009)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 2, 'criterion': 'entropy', 'max_features': 10, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.933 (std: 0.013)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 3, 'min_samples_split': 3, 'criterion': 'gini', 'max_features': 10, 'max_depth': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.grid_scores_)))\n",
    "report(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* The randomized search and the grid search explore exactly the same space of parameters.\n",
    "* The result in parameter settings is quite similar, while the run time for randomized search can be drastically lower.\n",
    "* The performance is slightly worse for the randomized search, though this is most likely a noise effect and would not carry over to a held-out test set.\n",
    "* Note that in practice, one would not search over this many different parameters simultaneously using grid search, but pick only the ones deemed most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation with grid search and cross-validation\n",
    "\n",
    "* development set comprises only half of the available labeled data\n",
    "* the performance of the selected hyper-parameters and trained model is then measured on a dedicated evaluation set that was not used during the model selection step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.975 (+/-0.031) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.939 (+/-0.043) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.977 (+/-0.027) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.976 (+/-0.027) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}\n",
      "0.977 (+/-0.027) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.979 (+/-0.022) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.977 (+/-0.027) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "0.979 (+/-0.022) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}\n",
      "0.976 (+/-0.020) for {'kernel': 'linear', 'C': 1}\n",
      "0.976 (+/-0.020) for {'kernel': 'linear', 'C': 10}\n",
      "0.976 (+/-0.020) for {'kernel': 'linear', 'C': 100}\n",
      "0.976 (+/-0.020) for {'kernel': 'linear', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       129\n",
      "          1       0.94      0.97      0.96       124\n",
      "          2       1.00      0.99      1.00       120\n",
      "          3       0.98      0.99      0.98       129\n",
      "          4       0.98      1.00      0.99       120\n",
      "          5       0.96      0.95      0.95       140\n",
      "          6       0.99      0.99      0.99       127\n",
      "          7       0.99      0.99      0.99       116\n",
      "          8       0.95      0.93      0.94       128\n",
      "          9       0.97      0.95      0.96       125\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1258\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.972 (+/-0.034) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.937 (+/-0.045) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.976 (+/-0.029) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.974 (+/-0.031) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}\n",
      "0.976 (+/-0.029) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.978 (+/-0.025) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.976 (+/-0.029) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "0.978 (+/-0.025) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}\n",
      "0.974 (+/-0.021) for {'kernel': 'linear', 'C': 1}\n",
      "0.974 (+/-0.021) for {'kernel': 'linear', 'C': 10}\n",
      "0.974 (+/-0.021) for {'kernel': 'linear', 'C': 100}\n",
      "0.974 (+/-0.021) for {'kernel': 'linear', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       129\n",
      "          1       0.94      0.97      0.96       124\n",
      "          2       1.00      0.99      1.00       120\n",
      "          3       0.98      0.99      0.98       129\n",
      "          4       0.98      1.00      0.99       120\n",
      "          5       0.96      0.95      0.95       140\n",
      "          6       0.99      0.99      0.99       127\n",
      "          7       0.99      0.99      0.99       116\n",
      "          8       0.95      0.93      0.94       128\n",
      "          9       0.97      0.95      0.96       125\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1258\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5, scoring='%s_weighted' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
