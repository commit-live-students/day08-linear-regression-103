![GitHub Logo](https://s3.ap-south-1.amazonaws.com/greyatom-social/logo.png)

## Pre-Read
1. [Intro to Logistic Regression](http://www.kdnuggets.com/2016/08/primer-logistic-regression-part-1.html)
2. [What are hyperparameters?](https://www.quora.com/What-are-hyperparameters-in-machine-learning)
3. [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall)
4. [Logloss](http://www.exegetic.biz/blog/2015/12/making-sense-logarithmic-loss/)

## Learning Objectives
1. Understand Logistic Regression
2. Understand Gradient Descent in Logistic Regression
2. Get in-depth knowledge about the various Evaluation Metrics
3. Learn how to tune hyperparameters using Grid Search and Random Search

## Hands-on Skills

## Slides
@[gslides](1giY83HbAidEurz0I0kO-PnMR0mqpCIFpn6RQFxrw9c8)

## Notebooks

## Assignments

## Post Reads
1. [Grid Search vs Random Search](https://medium.com/rants-on-machine-learning/smarter-parameter-sweeps-or-why-grid-search-is-plain-stupid-c17d97a0e881)
2. [Random Search Paper](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)
3. [sklearn: comparison between grid search and random search](http://scikit-learn.org/0.17/auto_examples/model_selection/randomized_search.html)
4. [Hyperparameter Tuning](http://blog.sigopt.com/post/144221180573/evaluating-hyperparameter-optimization-strategies)